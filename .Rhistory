View(cutData)
cutData = data[order(-data$views),]
cutData = cutData[1:1000,
cutData = data[order(-data$views),]
cutData = cutData[1:1000,]
View(cutData)
require(clValid)
cutData = data[order(-data$views),]
cutData = cutData[1:1000,]
clValid <- clValid(cutData,2:6, clMethods = "kmeans", validation = "internal")
View(clValid)
summary(clValid)
clValid <- clValid(cutData,2:6, clMethods = c("kmeans","hierarchical","pam"), validation = "internal")
clValid <- clValid(cutData,2:6, clMethods = c("kmeans","hierarchical","pam"), validation = "internal")
summary(clValid)
optimalScores(clValid)
clc
## bringing Data In
allData = read.csv("USvideos.csv")
## Subsetting relevant columns
data = subset(allData, select = c("views", "likes", "dislikes", "comment_count"))
library(cluster)
par(mfrow = c(5, 2))
for (k in 2:6){
kmeans_result = kmeans(data,k)
hist(kmeans_result$cluster,main = paste("Cluster Distribution - K = ", k))
}
require(clValid)
cutData = data[order(-data$views),]
cutData = cutData[1:1000,]
clValid <- clValid(cutData,2:6, clMethods = c("kmeans","hierarchical","pam"), validation = "internal")
summary(clValid)
optimalScores(clValid)
install.packages("ggfortify")
?hclust
par(mfrow = c(3, 2))
for (k in 2:6){
kmeans_result = kmeans(data,k)
hist(kmeans_result$cluster,main = paste("Cluster Distribution - K = ", k))
}
autoplot(kmeans(data,2))
require(ggfortify)
autoplot(kmeans(data,2))
?autoplot.kmeans
autoplot(kmeans(data,2), data = data)
?hclust
autoplot(kmeans(data,3), data = data)
autoplot(hclust(dist(data, method = "euclidean")))
autoplot(kmeans(cutData,2), data = cutData)
autoplot(hclust(dist(cutData, method = "euclidean")), data = cutData)
## bringing Data In
allData = read.csv("USvideos.csv")
## Subsetting relevant columns
data = subset(allData, select = c("views", "likes", "dislikes", "comment_count"))
library(cluster)
par(mfrow = c(3, 2))
for (k in 2:6){
kmeans_result = kmeans(data,k)
hist(kmeans_result$cluster,main = paste("Cluster Distribution - K = ", k))
}
##K = 5 had the best distribution among clusters
require(clValid)
cutData = data[order(-data$views),]
cutData = cutData[1:1000,]
clValid <- clValid(cutData,2:6, clMethods = c("kmeans","hierarchical","pam"), validation = "internal")
summary(clValid)
optimalScores(clValid)
## According to CL Valid, based on connectivity
## k means ->  2 clusters,
## hierarchical -> 2 clusters
## PAM -> 3 clusters
require(ggfortify)
autoplot(kmeans(cutData,2), data = cutData)
setwd("C:/Users/nakul/OneDrive/Desktop/School/Spring2020/IE 332/Assignment3/Traffic-Machine-Learning")
read.csv("rawDF.csv")
data <- read.csv("rawDF.csv")
install.packages(dplyr)
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
require(dplyr)
data <- read.csv("rawDF.csv")
require(dplyr)
if(any(is.na(data))){
print("yes")
}else{
print("no")
}
num_data <- select_if(data, is.numeric)
View(num_data)
View(data)
setwd("C:/Users/nakul/OneDrive/Desktop/School/Spring2020/IE 332/Assignment3/Youtube-Data-Clustering")
?pam
autoplot(pam(cutData,2), data = cutData)
## bringing Data In
allData = read.csv("USvideos.csv")
## Subsetting relevant columns
data = subset(allData, select = c("views", "likes", "dislikes", "comment_count"))
library(cluster)
par(mfrow = c(3, 2))
for (k in 2:6){
kmeans_result = kmeans(data,k)
hist(kmeans_result$cluster,main = paste("Cluster Distribution - K = ", k))
}
##K = 5 had the best distribution among clusters
require(clValid)
cutData = data[order(-data$views),]
cutData = cutData[1:1000,]
clValid <- clValid(cutData,2:6, clMethods = c("kmeans","hierarchical","pam"), validation = "internal")
summary(clValid)
## According to CL Valid, based on connectivity
## k means ->  2 clusters,
## hierarchical -> 2 clusters
## PAM -> 3 clusters
require(ggfortify)
autoplot(kmeans(cutData,2), data = cutData)
autoplot(pam(cutData,2), data = cutData)
?hclust
plot(hclust(dist(cutData, method = "euclidean")))
require(ggfortify)
autoplot(kmeans(cutData,2), data = cutData)
plot(hclust(dist(cutData, method = "euclidean")))
autoplot(pam(cutData,2), data = cutData)
?autoplot
require(ggfortify)
autoplot(kmeans(cutData,2), data = cutData, title = "K-Means Clusters")
plot(hclust(dist(cutData, method = "euclidean")))
autoplot(pam(cutData,2), data = cutData, title = "PAM Clusters")
autoplot(kmeans(cutData,2), data = cutData, main = "K-Means Clusters")
require(ggfortify)
autoplot(kmeans(cutData,2), data = cutData, main = "K-Means Clusters")
plot(hclust(dist(cutData, method = "euclidean")))
autoplot(pam(cutData,2), data = cutData, title = "PAM Clusters")
library(cluster)
par(mfrow = c(3, 2))
for (k in 2:6){
kmeans_result = kmeans(data,k)
hist(kmeans_result$cluster,main = paste("Cluster Distribution - K = ", k))
}
require(ggfortify)
autoplot(kmeans(data,2), data = data, main = "K-Means Clusters")
plot(hclust(dist(data, method = "euclidean")))
autoplot(pam(data,2), data = data, title = "PAM Clusters")
require(ggfortify)
autoplot(kmeans(cutData,2), data = cutData, main = "K-Means Clusters")
plot(hclust(dist(cutData, method = "euclidean")))
autoplot(pam(cutData,2), data = cutData, title = "PAM Clusters")
require(ggfortify)
autoplot(kmeans(cutData,2), data = cutData, main = "K-Means Clusters")
plot(hclust(dist(cutData, method = "euclidean")))
autoplot(pam(cutData,2), data = cutData, main = "PAM Clusters")
require(ggfortify)
autoplot(kmeans(cutData,2), data = cutData, main = "K-Means Clusters")
plot(hclust(dist(cutData, method = "euclidean")))
autoplot(pam(cutData,3), data = cutData, main = "PAM Clusters")
## bringing Data In
allData = read.csv("USvideos.csv")
## Subsetting relevant columns
data = subset(allData, select = c("views", "likes", "dislikes", "comment_count"))
library(cluster)
par(mfrow = c(3, 2))
for (k in 2:6){
kmeans_result = kmeans(data,k)
hist(kmeans_result$cluster,main = paste("Cluster Distribution - K = ", k))
}
# Taking a first look at the histograms of the clusters doesnt tell us much
##K = 5 had the best distribution among clusters
require(clValid)
cutData = data[order(-data$views),]
cutData = cutData[1:1000,]
clValid <- clValid(cutData,2:6, clMethods = c("kmeans","hierarchical","pam"), validation = "internal")
summary(clValid)
## According to CL Valid, based on connectivity
## k means ->  2 clusters,
## hierarchical -> 2 clusters
## PAM -> 3 clusters
require(ggfortify)
autoplot(kmeans(cutData,2), data = cutData, main = "K-Means Clusters")
plot(hclust(dist(cutData, method = "euclidean")))
autoplot(pam(cutData,3), data = cutData, main = "PAM Clusters")
require(ggfortify)
autoplot(kmeans(cutData,2), data = cutData, main = "K-Means Clusters")
plot(hclust(dist(cutData, method = "euclidean")))
autoplot(pam(cutData,3), data = cutData, main = "PAM Clusters")
par(mfrow = c(3, 2))
for (k in 2:6){
kmeans_result = kmeans(data,k)
hist(kmeans_result$cluster,main = paste("Cluster Distribution - K = ", k))
}
require(clValid)
cutData = data[order(-data$views),]
cutData = cutData[1:1000,]
clValid <- clValid(cutData,2:6, clMethods = c("kmeans","hierarchical","pam"), validation = "internal")
y
summary(clValid)
setwd("C:/Users/nakul/OneDrive/Desktop/School/Spring2020/IE 332/Assignment3/Traffic-Machine-Learning")
?select_if
data <- read.csv("rawDF.csv")
require(dplyr)
if(any(is.na(data))){
print("yes")
}else{
print("no")
}
num_data <- select_if(data, is.numeric)
data <- read.csv("rawDF.csv")
require(dplyr)
if(any(is.na(data))){
print("yes")
}else{
print("no")
}
num_data <- select_if(data, is.numeric)
View(data)
?length
data <- read.csv("rawDF.csv")
require(dplyr)
if(any(is.na(data))){
print("yes")
}else{
print("no")
}
numericDF<- select_if(data, is.numeric)
numericDF2 = data.frame()
for(i in 1:ncol(numericDF)){
x = (numericDF2[,i]  - min(numericDF2[,i]))/(max(numericDF2[,i]) - min(numericDF2[,i]))
numericDF2 = cbind(numericDF2,x)
}
##(x − min(A))/(max(A) − min(A))
data <- read.csv("rawDF.csv")
require(dplyr)
if(any(is.na(data))){
print("yes")
}else{
print("no")
}
numericDF<- select_if(data, is.numeric)
numericDF2 = data.frame()
for(i in 1:ncol(numericDF)){
x = (numericDF[,i]  - min(numericDF[,i]))/(max(numericDF[,i]) - min(numericDF[,i]))
numericDF2 = cbind(numericDF2,x)
}
##(x − min(A))/(max(A) − min(A))
numericDF<- select_if(data, is.numeric)
numericDF2 = data.frame()
for(i in 1:ncol(numericDF)){
numericDF2[,i] = (numericDF[,i]  - min(numericDF[,i]))/(max(numericDF[,i]) - min(numericDF[,i]))
}
numericDF<- select_if(data, is.numeric)
numericDF2 <- numericDF1
for(i in 1:ncol(numericDF)){
numericDF2[,i] = (numericDF2[,i]  - min(numericDF2[,i]))/(max(numericDF2[,i]) - min(numericDF2[,i]))
}
View(numericDF2)
data <- read.csv("rawDF.csv")
require(dplyr)
if(any(is.na(data))){
print("yes")
}else{
print("no")
}
numericDF<- select_if(data, is.numeric)
numericDF2 <- numericDF1
data <- read.csv("rawDF.csv")
require(dplyr)
if(any(is.na(data))){
print("yes")
}else{
print("no")
}
numericDF<- select_if(data, is.numeric)
numericDF2 <- numericDF
data <- read.csv("rawDF.csv")
require(dplyr)
if(any(is.na(data))){
print("yes")
}else{
print("no")
}
numericDF<- select_if(data, is.numeric)
numericDF2 <- numericDF
for(i in 1:ncol(numericDF)){
numericDF2[,i] = (numericDF2[,i]  - min(numericDF2[,i]))/(max(numericDF2[,i]) - min(numericDF2[,i]))
}
View(numericDF2)
data <- read.csv("rawDF.csv")
require(dplyr)
if(any(is.na(data))){
print("yes")
}else{
print("no")
}
numericDF<- select_if(data, is.numeric)
numericDF2 <- numericDF
for(i in 1:ncol(numericDF)){
numericDF2[,i] = (numericDF2[,i]  - min(numericDF2[,i]))/(max(numericDF2[,i]) - min(numericDF2[,i]))
}
##(x − min(A))/(max(A) − min(A))
View(numericDF2)
numericDF2 <- numericDF[!numericDF$traffic]
View(numericDF2)
View(numericDF2)
numericDF2 <- subset(numericDF, -"traffic")
numericDF2 <- subset(numericDF, select = -"traffic")
numericDF2 <- subset(numericDF, select = -c("traffic"))
numericDF2 <- subset(numericDF, select = -numericDF$traffic)
View(numericDF2)
data <- read.csv("rawDF.csv")
require(dplyr)
if(any(is.na(data))){
print("yes")
}else{
print("no")
}
numericDF<- select_if(data, is.numeric)
numericDF2 <- subset(numericDF, select = -numericDF$traffic)
for(i in 1:ncol(numericDF)){
numericDF2[,i] = (numericDF2[,i]  - min(numericDF2[,i]))/(max(numericDF2[,i]) - min(numericDF2[,i]))
}
numericDF2 = cbind(numericDF2, numericDF["traffic"])
##(x − min(A))/(max(A) − min(A))
View(numericDF2)
View(numericDF)
install.packages("caret")
splitVec <- createDataPartition(numericDF2$h.label, p = 0.75, list = F)
require(caret)
splitVec <- createDataPartition(numericDF2$h.label, p = 0.75, list = F)
View(numericDF2)
View(splitVec)
trainSet <- numericDF2[splitVec,]
testSet<- numericDF2[-splitVec,]
View(trainSet)
View(splitVec)
table(trainset)
table(trainSet)
calcRMSE<- function(predV, obV){
myRMSE = sum(( predV - obV)^2 / length(predV))
}
calcRMSE(c(2,2,2), c(1,1,1))
hi = calcRMSE(c(2,2,2), c(1,1,1))
install.packages("rpart")
require(rpart)
mytree <- rpart(
trainSet$traffic ~ trainSet$conds + trainSet$hour + trainSet$month_of_data +
trainSet$day_of_data + trainSet$day_of_week + trainSet$snow + trainSet$tempi + trainSet$visi +
trainSet$h.label + trainSet$wind_speed,
method = "class"
)
View(mytree)
?predict
predict.rpart
?predict.rpart
result <- predict(mytree, testSet[-testSet$traffic])
View(result)
result <- predict(mytree, testSet)
result <- predict(mytree, newdata=testSet)
result <- predict(mytree, type = "vector", newdata=testSet)
result <- predict(mytree, type = "matrix", newdata=testSet)
mytree <- rpart(
trainSet$traffic ~ trainSet$conds + trainSet$hour + trainSet$month_of_data +
trainSet$day_of_data + trainSet$day_of_week + trainSet$snow + trainSet$tempi + trainSet$visi +
trainSet$h.label + trainSet$wind_speed,
method = "matrix"
)
result <- predict(mytree, type = "matrix", newdata=testSet)
result <- predict(mytree, type = "class", newdata=testSet)
View(result)
data <- read.csv("rawDF.csv")
require(dplyr)
if(any(is.na(data))){
print("yes")
}else{
print("no")
}
numericDF<- select_if(data, is.numeric)
numericDF2 <- subset(numericDF, select = -numericDF$traffic)
for(i in 1:ncol(numericDF)){
numericDF2[,i] = (numericDF2[,i]  - min(numericDF2[,i]))/(max(numericDF2[,i]) - min(numericDF2[,i]))
}
numericDF2 = cbind(numericDF2, numericDF["traffic"])
##(x − min(A))/(max(A) − min(A))
require(caret)
splitVec <- createDataPartition(numericDF2$h.label, p = 0.75, list = F)
trainSet <- numericDF2[splitVec,]
testSet<- numericDF2[-splitVec,]
calcRMSE<- function(predV, obV){
myRMSE = sum(( predV - obV)^2 / length(predV))
}
require(rpart)
mytree <- rpart(
trainSet$traffic ~.,
method = "class"
)
result <- predict(mytree, type = "class", newdata=testSet)
data <- read.csv("rawDF.csv")
require(dplyr)
if(any(is.na(data))){
print("yes")
}else{
print("no")
}
numericDF<- select_if(data, is.numeric)
numericDF2 <- subset(numericDF, select = -numericDF$traffic)
for(i in 1:ncol(numericDF)){
numericDF2[,i] = (numericDF2[,i]  - min(numericDF2[,i]))/(max(numericDF2[,i]) - min(numericDF2[,i]))
}
numericDF2 = cbind(numericDF2, numericDF["traffic"])
##(x − min(A))/(max(A) − min(A))
require(caret)
splitVec <- createDataPartition(numericDF2$h.label, p = 0.75, list = F)
trainSet <- numericDF2[splitVec,]
testSet<- numericDF2[-splitVec,]
calcRMSE<- function(predV, obV){
myRMSE = sum(( predV - obV)^2 / length(predV))
}
require(rpart)
mytree <- rpart(
trainSet$traffic ~., data = trainSet,
method = "class"
)
result <- predict(mytree, type = "class", newdata=testSet)
View(mytree)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
# plot mytree
fancyRpartPlot(mytree, caption = NULL)
install.packages("rattle")
library(rattle)
library(rpart.plot)
library(RColorBrewer)
require(rattle)
# plot mytree
fancyRpartPlot(mytree, caption = NULL)
require(rpart)
mytree <- rpart(
trainSet$traffic ~., data = trainSet,
method = "class"
)
library(rattle)
library(RColorBrewer)
require(rattle)
# plot mytree
fancyRpartPlot(mytree, caption = NULL)
mytree <- rpart(trainSet$traffic ~., data = trainSet)
require(rattle)
require(RColorBrewer)
require(rattle)
require(RColorBrewer)
fancyRpartPlot(mytree)
require(rattle)
require(RColorBrewer)
fancyRpartPlot(mytree)
result <- predict(mytree, newdata=testSet)
obj_val = calcRMSE(result, testSet$traffic)
data <- read.csv("rawDF.csv")
require(dplyr)
if(any(is.na(data))){
print("yes")
}else{
print("no")
}
numericDF<- select_if(data, is.numeric)
numericDF2 <- subset(numericDF, select = -numericDF$traffic)
for(i in 1:ncol(numericDF)){
numericDF2[,i] = (numericDF2[,i]  - min(numericDF2[,i]))/(max(numericDF2[,i]) - min(numericDF2[,i]))
}
numericDF2 = cbind(numericDF2, numericDF["traffic"])
##(x − min(A))/(max(A) − min(A))
require(caret)
splitVec <- createDataPartition(numericDF2$h.label, p = 0.75, list = F)
trainSet <- numericDF2[splitVec,]
testSet<- numericDF2[-splitVec,]
calcRMSE<- function(predV, obV){
myRMSE = sum(( predV - obV)^2 / length(predV))
}
require(rpart)
require(rattle)
require(RColorBrewer)
mytree <- rpart(trainSet$traffic ~., data = trainSet)
fancyRpartPlot(mytree)
result <- predict(mytree, newdata=testSet)
obj_val = calcRMSE(result, testSet$traffic)
data <- read.csv("rawDF.csv")
require(dplyr)
if(any(is.na(data))){
print("yes")
}else{
print("no")
}
numericDF<- select_if(data, is.numeric)
numericDF2 <- subset(numericDF, select = -numericDF$traffic)
for(i in 1:ncol(numericDF)){
numericDF2[,i] = (numericDF2[,i]  - min(numericDF2[,i]))/(max(numericDF2[,i]) - min(numericDF2[,i]))
}
numericDF2 = cbind(numericDF2, numericDF["traffic"])
##(x − min(A))/(max(A) − min(A))
require(caret)
splitVec <- createDataPartition(numericDF2$h.label, p = 0.75, list = F)
trainSet <- numericDF2[splitVec,]
testSet<- numericDF2[-splitVec,]
calcRMSE<- function(predV, obV){
myRMSE = sum(( predV - obV)^2 / length(predV))
}
require(rpart)
require(rattle)
require(RColorBrewer)
mytree <- rpart(trainSet$traffic ~., data = trainSet)
fancyRpartPlot(mytree)
result <- predict(mytree, newdata=testSet)
obj_val = calcRMSE(result, testSet$traffic)
print(paste("The RMSE is: ", obj_val))
